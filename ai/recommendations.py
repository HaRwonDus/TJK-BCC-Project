import pandas as pd
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
import csv

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ª–µ–Ω–∏–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
model_name = "EleutherAI/gpt-neo-125M"
tokenizer = None
model = None

def _load_model():
    """–õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ò–ò"""
    global tokenizer, model
    if tokenizer is None or model is None:
        print("ü§ñ –ó–∞–≥—Ä—É–∂–∞–µ–º –ò–ò –º–æ–¥–µ–ª—å...")
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForCausalLM.from_pretrained(model_name)
        print("‚úÖ –ò–ò –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

def llm_generate_push(name, product, top_categories, benefit_sum):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—É—à-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –ò–ò"""
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ
    _load_model()
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    if isinstance(top_categories, str):
        top_categories = [cat.strip() for cat in top_categories.split(",")]
    elif not top_categories:
        top_categories = ["–û–±—â–∏–µ —Ç—Ä–∞—Ç—ã"]
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    top_categories = top_categories[:3]

    prompt = f"""
–ò–º—è –∫–ª–∏–µ–Ω—Ç–∞: {name}
–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø—Ä–æ–¥—É–∫—Ç: {product}
–¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç—Ä–∞—Ç: {', '.join(top_categories)}
–û–∂–∏–¥–∞–µ–º–∞—è –≤—ã–≥–æ–¥–∞: {benefit_sum:.0f} ‚Ç∏

–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ push-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ:
- –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –ø–æ –¥–µ–ª—É
- 180‚Äì220 —Å–∏–º–≤–æ–ª–æ–≤
- c CTA
- —Ä–µ–¥–ø–æ–ª–∏—Ç–∏–∫–∞: –±–µ–∑ –∫–∞–ø—Å–∞, –º–∞–∫—Å–∏–º—É–º 1 –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π, emoji ‚Äî 0‚Äì1
- –î–∞—Ç–∞ –¥–¥.–º–º.–≥–≥–≥–≥ (–∏–ª–∏ ¬´30 –∞–≤–≥—É—Å—Ç–∞ 2025¬ª ‚Äî –≥–¥–µ —É–º–µ—Å—Ç–Ω–æ)
- –°–æ–±–ª—é–¥–∞–π —Ñ–æ—Ä–º–∞—Ç —á–∏—Å–µ–ª (—Ä–∞–∑—Ä—è–¥—ã –ø—Ä–æ–±–µ–ª–æ–º, –¥—Ä–æ–±–∏ ‚Äî —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é), –≤–∞–ª—é—Ç—É ‚Äî —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ —Å–∏–º–≤–æ–ª–æ–º (‚Ç∏)
- CTA ‚Äî ¬´–û—Ç–∫—Ä—ã—Ç—å¬ª, ¬´–ù–∞—Å—Ç—Ä–æ–∏—Ç—å¬ª –∏–ª–∏ ¬´–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å¬ª

Push: """
    
    try:
        input_ids = tokenizer(prompt, return_tensors="pt").input_ids
        with torch.no_grad():
            generated_ids = model.generate(
                input_ids,
                max_length=input_ids.shape[1] + 50,
                do_sample=True,
                top_k=50,
                top_p=0.95,
                temperature=0.8,
                pad_token_id=tokenizer.eos_token_id,
                num_return_sequences=1
            )
        output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)
        push = output.split("Push:")[1].strip().split("\n")[0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—É—à –Ω–µ –ø—É—Å—Ç–æ–π
        if not push or len(push.strip()) < 10:
            return f"{name}, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º {product}. –û—Ñ–æ—Ä–º–∏—Ç—å —Å–µ–π—á–∞—Å."
        
        return push
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ò–ò –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        # Fallback —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
        return f"{name}, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º {product}. –û—Ñ–æ—Ä–º–∏—Ç—å —Å–µ–π—á–∞—Å."
